{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribución del Repositorio\n",
    "\n",
    "```\n",
    "|- app\n",
    "|  |- model\n",
    "|  |  |- Dockerfile\n",
    "|  |  |- Main.py\n",
    "|  |  |- requirements.txt\n",
    "|  |\n",
    "|  |- ui\n",
    "|     |- Dockerfile\n",
    "|     |- Main.py\n",
    "|     |- requirements.txt\n",
    "|  \n",
    "|  # Contiene la aplicación que ejecuta el modelo en contenedores.\n",
    "|  # - `model`: Backend de la aplicación.\n",
    "|  # - `ui`: Frontend de la aplicación.\n",
    "\n",
    "|- docker-compose\n",
    "|  # Archivo para orquestar los contenedores.\n",
    "\n",
    "|- data\n",
    "|  |- clean_data\n",
    "|  |  # CSV post limpieza y preparado para el modelado.\n",
    "|  |\n",
    "|  |- raw_data\n",
    "|  |  # Datos originales en formato JSON.\n",
    "|  |\n",
    "|  |- transformed_data\n",
    "|     # Datos estructurados según los requisitos del modelo.\n",
    "\n",
    "|- notebooks\n",
    "|  |- DataWrangling.ipynb\n",
    "|  |  # Limpieza y preprocesamiento de datos.\n",
    "|  |\n",
    "|  |- EDA.ipynb\n",
    "|  |  # Análisis descriptivo de los datos.\n",
    "|  |\n",
    "|  |- Experiments.ipynb\n",
    "|  |  # Pruebas de modelos y selección del más adecuado.\n",
    "|  |\n",
    "|  |- Pipeline.py\n",
    "|     # Flujo de Prefect para registrar y reentrenar modelos cuando sea necesario.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #2E86C1; text-align: center;\">Data Wrangling</h1>\n",
    "\n",
    "<p style=\"color: #34495E; font-size: 16px; line-height: 1.6;\">\n",
    "    <strong>Comencé este examen</strong> siguiendo los pasos para la lectura y preprocesado inicial del dataset: \n",
    "    tomé el <code>Json</code>, lo normalicé, recorté el dataset a las variables de importancia, las renombré, \n",
    "    hice el <i>feature engineering</i> para la variable de respuesta y comencé a ir y venir al EDA para obtener insights.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #2874A6; font-size: 16px; line-height: 1.6;\">\n",
    "    Primero hice limpieza clásica de textos:\n",
    "    <ul>\n",
    "        <li>Eliminé todo lo que no fuera alfanumérico.</li>\n",
    "        <li>Estandaricé a minúsculas.</li>\n",
    "        <li>Expandí contracciones.</li>\n",
    "        <li>Quité <i>stopwords</i>.</li>\n",
    "    </ul>\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #148F77; font-size: 16px; line-height: 1.6;\">\n",
    "    Después, cuando comencé a checar el EDA, noté que había palabras que eran casi constantes a lo largo de todas las quejas.\n",
    "    Así que decidí generar una función que recortara aquellas palabras que aparecieran en cierta cantidad de documentos, \n",
    "    y finalmente la dejé para el <b>80% de los documentos</b>.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #D68910; font-size: 16px; line-height: 1.6;\">\n",
    "    Casi para terminar, noté que había categorías con muy pocos registros, \n",
    "    así que tomé un enfoque similar al de las palabras muy repetidas y eliminé todas aquellas categorías con un conteo de registros menor a <b>10</b>.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #76448A; font-size: 16px; line-height: 1.6;\">\n",
    "    Por último, apliqué ambos métodos en <i>batch processing</i> y guardé un <b>save state</b> del dataset en <code>transformed data</code>.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #2E86C1; text-align: center;\">EDA</h1>\n",
    "\n",
    "<p style=\"color: #34495E; font-size: 16px; line-height: 1.6;\">\n",
    "    El <b>EDA</b> fue mi guía para el <i>data wrangling</i>, ya que los insights que iba obteniendo me servían para la limpieza. \n",
    "    Entre lo más relevante está:\n",
    "    <ul>\n",
    "        <li>Notar las clases con pocos registros.</li>\n",
    "        <li>Identificar muchas <i>stopwords</i>.</li>\n",
    "        <li>Detectar palabras muy repetidas.</li>\n",
    "    </ul>\n",
    "    Fue un proceso iterativo, pero finalmente dejé limpio el dataset y procedí a la visualización.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #2874A6; font-size: 16px; line-height: 1.6;\">\n",
    "    Para ello reutilicé una función que ya había hecho hace tiempo para graficar un <b>wordcloud</b> por cada categoría junto a una colección del <b>top 10</b>:\n",
    "    <ol>\n",
    "        <li>Unigramas.</li>\n",
    "        <li>Bigramas.</li>\n",
    "        <li>Trigramas.</li>\n",
    "    </ol>\n",
    "    Esto permitió evaluar qué tan distintas eran las categorías después de la limpieza, y los resultados fueron satisfactorios.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #2E86C1; text-align: center;\">Experimentación</h1>\n",
    "\n",
    "<p style=\"color: #34495E; font-size: 16px; line-height: 1.6;\">\n",
    "    Para el modelado, comencé siguiendo lo que aprendí en minería de textos. Pensaba en utilizar \n",
    "    <b>regresión logística</b> y <b>random forest</b>, porque ambos me dieron muy buenos resultados en esa clase.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #2874A6; font-size: 16px; line-height: 1.6;\">\n",
    "    Utilicé <b>TF-IDF</b> (<i>Term Frequency-Inverse Document Frequency</i>) para vectorizar los textos, ya que va muy bien con \n",
    "    el tipo de limpieza que había utilizado.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #148F77; font-size: 16px; line-height: 1.6;\">\n",
    "    En la primera iteración del modelado me fue bastante bien, pero tuve un problema con el encodeado de las etiquetas y \n",
    "    con la vectorización del texto. A la hora de pasar un nuevo <i>input</i>, no estaba codificado en la matriz de frecuencia directa e inversa.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #D68910; font-size: 16px; line-height: 1.6;\">\n",
    "    Así que tuve que rehacer el modelado, definiendo un <b>pipeline</b> que implementara el vectorizador y, posteriormente, \n",
    "    lo loggeara como artefacto para cuando necesitara predecir con el modelo desde <b>MLflow</b>.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #76448A; font-size: 16px; line-height: 1.6;\">\n",
    "    Estuve jugando mucho con los <i>grid search</i> y mis modelos, pero finalmente decidí quedarme con:\n",
    "    <ul>\n",
    "        <li>Penalización <b>L2</b>.</li>\n",
    "        <li>Un solver que combinara con esta penalización.</li>\n",
    "        <li>Un <i>cross-validation</i> de <b>5</b>.</li>\n",
    "        <li><b>Verbose</b> de 1 y 2 (aunque este último no tuvo impacto contrario a lo que esperaba).</li>\n",
    "    </ul>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #2E86C1; text-align: center;\">Pipeline</h1>\n",
    "\n",
    "<p style=\"color: #34495E; font-size: 16px; line-height: 1.6;\">\n",
    "    Para el <b>pipeline</b>, simplemente desmenucé lo que ya tenía en la experimentación, pero solo implementando \n",
    "    la <b>regresión logística</b>.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #2874A6; font-size: 16px; line-height: 1.6;\">\n",
    "    Además, añadí la tarea <code>SetChamp</code> para tomar el resultado de la función <code>getBestModel</code> y \n",
    "    convertirlo en <b>champion</b>. También cambié la etiqueta por <code>champ</code> para que fuera más fácil identificarla entre todos los modelos.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #148F77; font-size: 16px; line-height: 1.6;\">\n",
    "    Corrí el flujo y todo funcionó <b>perfecto</b>.\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #2E86C1; text-align: center;\">App</h1>\n",
    "\n",
    "<p style=\"color: #34495E; font-size: 16px; line-height: 1.6;\">\n",
    "    Finalmente, para el desarrollo de la <b>app</b>, tomé lo que ya habíamos generado para <i>nyc-taxi-model</i> e hice unos cuantos ajustes en el <code>yaml</code> y los <code>.py</code>.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #2874A6; font-size: 16px; line-height: 1.6;\">\n",
    "    Esta parte me generó algo de conflicto, especialmente porque, siguiendo la lógica de <i>taxi model</i>, enviaba un diccionario, \n",
    "    y tuve problemas para extraerlo y pasárselo al modelo aunque solo tuviera un valor.\n",
    "</p>\n",
    "\n",
    "<p style=\"color: #148F77; font-size: 16px; line-height: 1.6;\">\n",
    "    Estaba considerando usar un <code>zip</code>, pero luego me di cuenta de que, al ser solo una variable predictora, \n",
    "    podía enviarla directamente al <b>back</b>. Así lo implementé, hice pruebas, y <b>funciona perfecto</b>.\n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
