{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripción General del Proyecto\n",
    "El objetivo de este proyecto fue construir, desplegar y probar un pipeline de machine learning y una API REST basada en FastAPI para tareas de clasificación de texto. El proyecto también incluyó la integración del sistema con MLflow para el seguimiento de experimentos y el despliegue de los servicios utilizando Docker Compose. El pipeline fue diseñado para entrenar modelos con diferentes algoritmos (Naive Bayes y KNN), y la API fue configurada para servir predicciones basadas en estos modelos.\n",
    "\n",
    "Pasos Realizados\n",
    "1. Construcción del Pipeline de Machine Learning\n",
    "Se creó un pipeline con los siguientes pasos:\n",
    "\n",
    "Lectura y Preprocesamiento de Datos:\n",
    "\n",
    "Se cargaron los datos desde un archivo CSV (final_df.csv).\n",
    "Se gestionaron valores faltantes y se limpió el texto en las columnas relevantes.\n",
    "Ingeniería de Características:\n",
    "\n",
    "Se combinaron las columnas de texto relevantes (cleaned_complaint y ticket_classification) en un único campo de texto.\n",
    "Se procesaron los textos mediante tokenización, eliminación de stopwords y vectorización con TfidfVectorizer.\n",
    "Entrenamiento de Modelos:\n",
    "\n",
    "Se entrenaron un Naive Bayes Classifier y un KNN Classifier utilizando ajuste de hiperparámetros con Hyperopt.\n",
    "Se registraron el rendimiento de los modelos y sus parámetros en MLflow.\n",
    "Se guardaron el modelo entrenado y el vectorizador (TfidfVectorizer) para su uso posterior.\n",
    "Registro de Modelos y Seguimiento de Experimentos:\n",
    "\n",
    "Se registraron el modelo y el vectorizador como artefactos en MLflow.\n",
    "Se asignó el modelo con mejor rendimiento como el Modelo Campeón (Champion) y el segundo mejor como el Modelo Retador (Challenger).\n",
    "2. Desarrollo y Despliegue de la API REST con FastAPI\n",
    "Se desarrolló una API REST con FastAPI para servir predicciones basadas en los modelos entrenados:\n",
    "\n",
    "Endpoints:\n",
    "\n",
    "GET /: Endpoint para verificar que la API está corriendo.\n",
    "POST /predict: Acepta un JSON de entrada (cleaned_complaint y ticket_classification) y devuelve el tema (topic) predicho.\n",
    "Preprocesamiento en la API:\n",
    "\n",
    "Se cargó el vectorizador (TfidfVectorizer) guardado durante el entrenamiento y se utilizó para transformar el texto de entrada.\n",
    "Se utilizó el modelo Naive Bayes registrado en MLflow para predecir el tema (predicted_topic).\n",
    "Pruebas:\n",
    "\n",
    "Se probaron los endpoints utilizando Postman y curl para garantizar que devolvieran predicciones correctas.\n",
    "3. Integración con Docker\n",
    "Se configuraron y desplegaron los servicios de FastAPI y MLflow utilizando Docker Compose:\n",
    "\n",
    "Dockerfile:\n",
    "\n",
    "Se configuró un contenedor basado en Python para ejecutar la aplicación FastAPI.\n",
    "Se instalaron todas las dependencias del proyecto desde un archivo requirements.txt.\n",
    "Se configuró el directorio de trabajo como /app y se expuso el puerto 8000.\n",
    "docker-compose.yaml:\n",
    "\n",
    "Se configuraron dos servicios:\n",
    "api: Servicio para alojar la API FastAPI en el puerto 8000.\n",
    "mlflow: Servicio para alojar MLflow en el puerto 5000 para el seguimiento de experimentos.\n",
    "Se montaron volúmenes para persistir datos de MLflow (mlruns) y para acceder al vectorizador guardado (vectorizer.pkl).\n",
    "Ejecución de Servicios:\n",
    "\n",
    "Los servicios se construyeron y se ejecutaron con:\n",
    "docker-compose build\n",
    "docker-compose up\n",
    "Conclusión\n",
    "El proyecto implementó con éxito un pipeline completo de Machine Learning, un sistema de predicción mediante una API REST y un seguimiento de experimentos con MLflow. El sistema está completamente contenedorizado, lo que facilita su despliegue y escalabilidad futura."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
