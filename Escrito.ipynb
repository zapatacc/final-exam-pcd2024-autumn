{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renata Paloma Orozco Lopez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccion:\n",
    "Este proyecto busca demostrar mi capacidad para llevar a cabo un ciclo completo de Ciencia de Datos, abordando un problema realista desde el análisis inicial hasta la implementación de una solución funcional.\n",
    "\n",
    "El trabajo comienza con la clonación y configuración del repositorio, seguido de la integración de MLflow para gestionar experimentos y registrar modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    " \n",
    "### 1. Limpieza y EDA\n",
    "Para la limpieza basicamente segui los pasos que se enceuntran en ExamenFinal.ipynb, se encuentra en la la carpeta notebooks con el nombre de limpieza_eda. \n",
    "Comencé cargando los datos en un DataFrame y seleccionando las columnas más relevantes. Renombré las columnas para mayor claridad y creé una nueva columna combinando category y sub_product para clasificar los tickets.\n",
    "\n",
    "Limpie el texto convirtiéndolo a minúsculas, eliminando caracteres y filas vacías. Luego exporté los datos limpios a un archivo CSV para futuros análisis.(practicamente como estan en las instruciones de examen)\n",
    "\n",
    "Realicé un análisis exploratorio, creando gráficos para visualizar la frecuencia de las categorías y la proporción de textos que contenían números. También analicé la longitud promedio de las quejas.\n",
    " \n",
    " \n",
    "---\n",
    " \n",
    "### 2. Estructura del Proyecto\n",
    " \n",
    "#### Modelo: \n",
    "+ El modelo se encuntra en la carpeta notebooks y tiene como nombre dagshub_model.\n",
    "Este código entrena y evalua un modelo de clasificación de texto usando Regresión Logística. \n",
    "Utilicé el framework MLflow para realizar un seguimiento de los experimentos y sus resultados\n",
    "+ Prepareacion de los datos: cargue los datos limpios, dividí  los datos de entrenamineto en un 70 y lo de prueba 30\n",
    "+ Para la transformación del texto, utilicé TfidfVectorizer para convertir los textos en representaciones numéricas basadas en el modelo TF-IDF\n",
    "+ Implementé GridSearchCV para encontrar los mejores hiperparámetros\n",
    "\n",
    "---\n",
    "\n",
    "#### 3.Orquestacion y Automatizacion\n",
    "\n",
    "+ Definí un flujo de trabajo en Prefect para entrenar y evaluar modelos de clasificación. \n",
    "+ Primero configuré DagsHub y MLflow, después, cargué los datos, los dividí en conjuntos de entrenamiento y prueba, y codifiqué las etiquetas. \n",
    "+ Entrené dos modelos, Logistic Regression y SVC.\n",
    "+ Evalué el desempeño de cada modelo con métricas como precisión y F1-score, y registré tanto los modelos como las métricas en MLflow.\n",
    "+ También creé un mapeo de etiquetas para entender los resultados y saque los dos mejores modelos como \"champion\" y \"challenger\".\n",
    "\n",
    "---\n",
    "\n",
    "#### 4.API\n",
    " \n",
    "La aplicación se encuntra en una sola carpeta denomida api y en esta se encuentran model y UI\n",
    " \n",
    "+ Model:\n",
    "  En el model, implementé el backend para procesar solicitudes y generar predicciones mediante un modelo preentrenado, en este caso, una regresión logística. conecte MLflow en DagsHub utilizando una URI específica para cargar el modelo. Para construir la API, utilicé FastAPI, donde definí un endpoint /predict que recibe la descripción de una queja y devuelve la categoría correspondiente.\n",
    " \n",
    "+ UI:\n",
    "  Creé la interfaz de usuario utilizando Streamlit conectada con FastAPI, el pricipal objetivo es que los usuarios pueden ingresar una descripción de su queja en un formulario y, al hacer clic en un botón, el sistema realiza la predicción. \n",
    "\n",
    "+ docker-compose.yaml\n",
    " Este archivo docker-compose.yml que creé configura dos servicios: uno para el frontend (interfaz de usuario) y otro para el backend (modelo de predicción)\n",
    "\n",
    "---\n",
    "#### Conclusion\n",
    "\n",
    "En conclusion he desarrollado una aplicación que integra un modelo de predicción con una interfaz de usuario sencilla y accesible. Utilizando Docker Compose, he logrado implementar los conceptos vistos en clase, lo que me ha permitido crear una solución robusta con el backend y el frontend en contenedores separados y comunicándose eficientemente. A lo largo del proyecto, he tenido errores, como problemas en la configuración de los contenedores o dificultades al conectar los servicios, pero cada uno de ellos me brindó la oportunidad de aprender y mejorar la implementación.\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    " \n",
    " \n",
    "\n",
    "\n",
    " \n",
    "\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
