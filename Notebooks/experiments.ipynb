{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e670f646-c89d-4706-b514-02466d68e19a",
   "metadata": {},
   "source": [
    "# Preparar datos y hacer diversos modelos \n",
    "\n",
    "Para poder hacer un buen modelo tenemos que seleccionar los parametros correctos adem谩s de hacer una limpieza adecuada, eso es lo que haremos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import  mean_squared_error\n",
    "from sklearn.feature_extraction import  DictVectorizer\n",
    "from sklearn.linear_model import Lasso, Ridge, LogisticRegression\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import dagshub\n",
    "import mlflow\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edec006f-9ca1-4d19-a676-5284f50f4c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>ticket_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
       "      <td>Debt collection + Credit card debt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
       "      <td>Credit card or prepaid card + General-purpose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Chase Card was reported on XX/XX/2019. However...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>On XX/XX/2018, while trying to book a XXXX  XX...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>my grand son give me check for {$1600.00} i de...</td>\n",
       "      <td>Checking or savings account + Checking account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18958</th>\n",
       "      <td>18958</td>\n",
       "      <td>My husband passed away. Chase bank put check o...</td>\n",
       "      <td>Checking or savings account + Checking account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18959</th>\n",
       "      <td>18959</td>\n",
       "      <td>After being a Chase Card customer for well ove...</td>\n",
       "      <td>Credit card or prepaid card + General-purpose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18960</th>\n",
       "      <td>18960</td>\n",
       "      <td>On Wednesday, XX/XX/XXXX I called Chas, my XXX...</td>\n",
       "      <td>Credit card or prepaid card + General-purpose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18961</th>\n",
       "      <td>18961</td>\n",
       "      <td>I am not familiar with XXXX pay and did not un...</td>\n",
       "      <td>Checking or savings account + Checking account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18962</th>\n",
       "      <td>18962</td>\n",
       "      <td>I have had flawless credit for 30 yrs. I've ha...</td>\n",
       "      <td>Credit card or prepaid card + General-purpose ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18963 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                            complaint_what_happened  \\\n",
       "0               0  Good morning my name is XXXX XXXX and I apprec...   \n",
       "1               1  I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
       "2               2  Chase Card was reported on XX/XX/2019. However...   \n",
       "3               3  On XX/XX/2018, while trying to book a XXXX  XX...   \n",
       "4               4  my grand son give me check for {$1600.00} i de...   \n",
       "...           ...                                                ...   \n",
       "18958       18958  My husband passed away. Chase bank put check o...   \n",
       "18959       18959  After being a Chase Card customer for well ove...   \n",
       "18960       18960  On Wednesday, XX/XX/XXXX I called Chas, my XXX...   \n",
       "18961       18961  I am not familiar with XXXX pay and did not un...   \n",
       "18962       18962  I have had flawless credit for 30 yrs. I've ha...   \n",
       "\n",
       "                                   ticket_classification  \n",
       "0                     Debt collection + Credit card debt  \n",
       "1      Credit card or prepaid card + General-purpose ...  \n",
       "2      Credit reporting, credit repair services, or o...  \n",
       "3      Credit reporting, credit repair services, or o...  \n",
       "4         Checking or savings account + Checking account  \n",
       "...                                                  ...  \n",
       "18958     Checking or savings account + Checking account  \n",
       "18959  Credit card or prepaid card + General-purpose ...  \n",
       "18960  Credit card or prepaid card + General-purpose ...  \n",
       "18961     Checking or savings account + Checking account  \n",
       "18962  Credit card or prepaid card + General-purpose ...  \n",
       "\n",
       "[18963 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/melanie/PycharmProjects/final-exam-pcd2024-autumn/raw_data/data.csv')\n",
    "#df = df[['complaint_what_happened', 'ticket_classification']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d41a1-f5de-49aa-a026-2ee8c8083ac7",
   "metadata": {},
   "source": [
    "Preprocesamiento del texto para mejorar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d639d71f-8491-4509-87dc-502ad0f507e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/melanie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Funci贸n para limpiar el texto\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r\"XX|xx\", \"\", text)  # Eliminar \"XX\"\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Mantener solo letras\n",
    "    text = text.lower()  # Convertir a min煤sculas\n",
    "    tokens = text.split()  # Tokenizar\n",
    "    tokens = [word for word in tokens if word not in stop_words]  # Eliminar stopwords\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "df['cleaned_text'] = df['complaint_what_happened'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc5df41-a8ec-43b7-bccf-e51c02e74642",
   "metadata": {},
   "source": [
    "Separar los los datos para entrenar los modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6048ec7e-f0b8-4a65-9c89-4549442c3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar datos en X (features) y y (target)\n",
    "X = df['cleaned_text']\n",
    "y = df['ticket_classification']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783aab8-7642-44d4-aecd-3cc4ca4d2599",
   "metadata": {},
   "source": [
    "Entrenamiento de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c13a6b98-e121-4f03-a979-36aeddc29008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5839704719219615\n"
     ]
    }
   ],
   "source": [
    "# Pipeline con TF-IDF y Logistic Regression\n",
    "tfidf_lr_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Entrenamiento y evaluaci贸n\n",
    "tfidf_lr_pipeline.fit(X_train, y_train)\n",
    "lr_accuracy = tfidf_lr_pipeline.score(X_test, y_test)\n",
    "print(\"Logistic Regression Accuracy:\", lr_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38ce5bde-f157-428d-8a92-a51cf4092dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.5599789085156868\n"
     ]
    }
   ],
   "source": [
    "# Vectorizaci贸n TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Modelo Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predicci贸n y evaluaci贸n\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "039f9862-6ee9-4be7-8a10-8da1100c1d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5958344318481413\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear pipeline para SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000)),  # Vectorizador TF-IDF\n",
    "    ('clf', SVC(kernel='linear', probability=True, random_state=42))  # SVM con kernel lineal\n",
    "])\n",
    "\n",
    "# Entrenar el modelo\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predicci贸n y evaluaci贸n\n",
    "y_pred_svm = svm_pipeline.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b429908b-0a52-43cc-83f7-010a61d3f834",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1846093420.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[50], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Carga de modelos a dagshub.\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Carga de modelos a dagshub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0a1fce9-2fd6-4dbf-9c6c-59ec409e229a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"zapatacc/final-exam-pcd2024-autumn\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"zapatacc/final-exam-pcd2024-autumn\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository zapatacc/final-exam-pcd2024-autumn initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository zapatacc/final-exam-pcd2024-autumn initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/02688bbbcea44e41a2c981a9aad1106e', creation_time=1732306000706, experiment_id='43', last_update_time=1732306000706, lifecycle_stage='active', name='melanie-michel', tags={}>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicializar conexi贸n con DagsHub\n",
    "dagshub.init(repo_owner='zapatacc', repo_name='final-exam-pcd2024-autumn', mlflow=True)\n",
    "\n",
    "# Configurar el tracking URI para MLflow\n",
    "TRACKING_URI = mlflow.get_tracking_uri()\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "\n",
    "# Definir el experimento\n",
    "mlflow.set_experiment(\"melanie-michel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ef618cc-2342-4db0-af67-e5586bae227a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/22 14:07:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " View run Logistic Regression Model at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/43/runs/349a456f84c04ccb96759c2d69458666\n",
      "И View experiment at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/43\n"
     ]
    }
   ],
   "source": [
    "#Registrar el modelo Logistic Regression\n",
    "with mlflow.start_run(run_name=\"Logistic Regression Model\") as run:\n",
    "    # Registrar par谩metros y m茅tricas\n",
    "    mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    mlflow.log_metric(\"accuracy\", lr_accuracy)\n",
    "\n",
    "    # Guardar el modelo\n",
    "    mlflow.sklearn.log_model(tfidf_lr_pipeline, \"logistic_regression_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80373e72-3fa3-4648-975d-9391ca23f5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/22 14:08:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " View run Random Forest Model at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/43/runs/4b3c02e377cc4fcca3a3cac258f9659c\n",
      "И View experiment at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/43\n"
     ]
    }
   ],
   "source": [
    "#registrar el modelo Random Forest\n",
    "with mlflow.start_run(run_name=\"Random Forest Model\") as run:\n",
    "    # Registrar par谩metros y m茅tricas\n",
    "    mlflow.log_param(\"model\", \"Random Forest\")\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_metric(\"accuracy\", rf_accuracy)\n",
    "\n",
    "    # Guardar el modelo\n",
    "    mlflow.sklearn.log_model(rf_model, \"random_forest_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "336ce3ec-1209-43ec-a8c4-297f1419d8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/22 14:41:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " View run SVM Model at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/43/runs/e2d52469966b4756b55a8ac12879656c\n",
      "И View experiment at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/43\n"
     ]
    }
   ],
   "source": [
    "# Registrar el modelo SVM en MLflow\n",
    "with mlflow.start_run(run_name=\"SVM Model\") as run:\n",
    "    # Registrar par谩metros y m茅tricas\n",
    "    mlflow.log_param(\"model\", \"Support Vector Machine\")\n",
    "    mlflow.log_param(\"kernel\", \"linear\")\n",
    "    mlflow.log_metric(\"accuracy\", svm_accuracy)\n",
    "\n",
    "    # Guardar el modelo\n",
    "    mlflow.sklearn.log_model(\n",
    "        svm_pipeline, \n",
    "        \"svm_model\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
