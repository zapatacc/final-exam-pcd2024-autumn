{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Reporte del trabajo\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En verdad me gustó mucho el proyecto, ya que fue muy completo y que integro todo lo visto en clase en un caso de aplicación real. Durante el desarrollo, implementé soluciones que abarcaban desde el análisis exploratorio de datos hasta la implementación de una UI para predecir la categoría en base a su texto, donde se incluyeron modelos de aprendizaje automático, una API para hacer predicciones en la UI, y se utilizaron herramientas como mlflow y dagsgub para el model registry, prefect para la orquestracion y Docker para la contenerización, además de estar constantemente trabajando con git.\n",
    "\n",
    "## EDA\n",
    "\n",
    "Lo primero que se hizo fue el EDA donde su función fue básicamente conocer el dataframe e identificar posibles patrones o anomalías que posteriormente sirvieron para hacer la limpieza de texto. Podriá decir que proporciono una comprensión clara del estado de los datos y guio las siguientes etapas del proyecto.\n",
    "\n",
    "## Data wrangling\n",
    "\n",
    "En la parte de data wranlgling que fue donde una de las partes mas importantes del proyecto, ya que prácticamente aquí se iba a definir el accuracy que iba a tener tu modelo, se incluyo el proceso de dejar solamente 2 columnas en el dataframe y limpiar el texto para que el modelo pudiera hacer una mejor predicción.\n",
    "\n",
    "## Model registry\n",
    "\n",
    "La siguiente parte fue la preparación de los datos, pero se incluyó en el notebook del model registry, esto incluyo que los textos procesados fueron vectorizados mediante TF-IDF, mientras que las categorías de salida se codificaron numéricamente con LabelEncoder. Estas transformaciones garantizaron un conjunto de datos listo para entrenar modelos de clasificación.\n",
    "\n",
    "El entrenamiento y evaluación de modelos fue una de las partes centrales del proyecto. Implementé dos algoritmos: regresión logística y random forest. A estos algoritmos le aplique un grid search y se iban registrando los diferentes modelos en el experimento creado y tomando como métrica el accuracy.  Al finalizar esta etapa, la regresión logística se registró como modelo \"Champion\" debido a su mejor desempeño y también se dejo el segundo mejor modelo asignado con el alías de” Challenger”.\n",
    "\n",
    "## Training pipeline\n",
    "\n",
    "Ya teniendo todo esto lo junte todo en la orquestación del flujo de trabajo que fue en un script de Python y utilizando prefect. Este script me permitió automatizar tareas como el preprocesamiento de datos, el entrenamiento, la evaluación y el registro de modelos. Diseñé un flujo que era muy fácil de ejecutar en mi computadora, y me asegure de que los modelos estuvieran correctamente registrados en MLflow, este fue la parte más difícil, ya que requirió de varios intentos, ya que al inicio no logeaba los artefactos y después no los logeaba de manera correcta, pero finalmente se logró. Este  script de Python mejoró la eficiencia del proyecto y demostró la importancia de automatizar procesos complejos en los diferentes proyectos de ciencia de datos.\n",
    "\n",
    "## Frontend y backend\n",
    "\n",
    "Una vea terminado el training pipeline, continue con el desarrollo del API utilizando FastAPI que servía el modelo Champion. La API contenía un endpoint que permitía enviar texto de entrada y obtener predicciones de la categoría correspondiente. Ya con el API diseñé un frontend sencillo con Streamlit. La interfaz permitía a los usuarios introducir texto y ver a que categoría perteneciia, conectándose directamente a la API para realizar las inferencias. Este componente mejoró la accesibilidad y usabilidad del sistema.\n",
    "\n",
    "## Contenerización\n",
    "\n",
    "Finalmente, integré todos los elementos en contenedores utilizando Docker. Creé un archivo docker-compose.yaml que permitía ejecutar tanto la API como el frontend en entornos aislados y consistentes. Este paso aseguró que el sistema completo pudiera desplegarse fácilmente en cualquier entorno sin problemas de configuración, mejorando la portabilidad del proyecto.\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "En conclusión, este proyecto fue una gran experiencia que consolidó mis habilidades adquiridas durante en curso y en la integración de estas nuevas herramientas para poder resolver los problemas que se me asignen en un futuro. Aprendí a hacer un proyecto totalmente apoyándome de git, cosa que nunca había hecho, pero debería de agarrar esa costumbre porque es una herramienta muy útil, además de ir paso a paso y trabajar de manera estructurada, con las carpetas bien ordenadas y los archivos en su dirección correcta, de tal manera que cualquier colaborador que quisiera formar parte del proyecto, pudiera entender la estructura de manera fácil y sencilla. Me encanto como se hizo todo en jupyter notebooks y ya que no hubiera fallas se orquestaba todo en el training pipeline utilizando prefect, me parece una muy buena metodología. También, como dije anteriormente, siento que este proyecto, termino de consolidar todas las habilidades adquiridas durante el curso y que tienen gran valor, como lo pueden ser MLflow, Prefect y Docker, y comprendí la importancia de una gestión efectiva de proyectos. Finalmente, podría decir que no solo requirió de habilidades técnicas este proyecto, también se requirió de habilidades de manejo de tiempo, organización y resolución de problemas.\n"
   ],
   "id": "feb4cf05275b60e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "457cd677da588568"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
