{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reading and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos librerías\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abrimos el json, lo cargamos y normalizamos\n",
    "file_path = \"../data/raw_data/tickets_classification_eng.json\"\n",
    "with open(file_path, \"r\") as file:  \n",
    "    datos = json.load(file)\n",
    "\n",
    "df = pd.json_normalize(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccionamos sólo las variables de interés\n",
    "df = df[['_source.complaint_what_happened', '_source.product', '_source.sub_product']]\n",
    "\n",
    "#Renombramos para facilitar el manejo de las columnas\n",
    "df = df.rename(columns={'_source.complaint_what_happened':'complaint_what_happened',\n",
    "                '_source.product':'category',\n",
    "                '_source.sub_product':'sub_product'\n",
    "                })\n",
    "\n",
    "#Creamos la nueva columna de clasificación\n",
    "df['ticket_classification'] = df['category'] + \" + \" + df['sub_product']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Debt collection', 'Credit card or prepaid card', 'Mortgage',\n",
       "       'Checking or savings account',\n",
       "       'Credit reporting, credit repair services, or other personal consumer reports',\n",
       "       'Vehicle loan or lease',\n",
       "       'Money transfer, virtual currency, or money service',\n",
       "       'Student loan', 'Consumer Loan', 'Credit card',\n",
       "       'Bank account or service',\n",
       "       'Payday loan, title loan, or personal loan', 'Money transfers',\n",
       "       'Credit reporting', 'Payday loan', 'Prepaid card',\n",
       "       'Other financial service'], dtype=object)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dropeamos columnas redundantes\n",
    "df = df.drop(['category', 'sub_product'], axis=1)\n",
    "\n",
    "#Llenamos los registros vacíos con nulos de pandas\n",
    "df['complaint_what_happened'] = df['complaint_what_happened'].replace(\"\", pd.NA)\n",
    "\n",
    "#Dropeamos los nulos\n",
    "df = df.dropna()\n",
    "\n",
    "#Reseteamos el index\n",
    "df = df.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>ticket_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning my name is XXXX XXXX and I apprec...</td>\n",
       "      <td>Debt collection + Credit card debt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I upgraded my XXXX XXXX card in XX/XX/2018 and...</td>\n",
       "      <td>Credit card or prepaid card + General-purpose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chase Card was reported on XX/XX/2019. However...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>On XX/XX/2018, while trying to book a XXXX  XX...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>my grand son give me check for {$1600.00} i de...</td>\n",
       "      <td>Checking or savings account + Checking account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              complaint_what_happened  \\\n",
       "1   Good morning my name is XXXX XXXX and I apprec...   \n",
       "2   I upgraded my XXXX XXXX card in XX/XX/2018 and...   \n",
       "10  Chase Card was reported on XX/XX/2019. However...   \n",
       "11  On XX/XX/2018, while trying to book a XXXX  XX...   \n",
       "14  my grand son give me check for {$1600.00} i de...   \n",
       "\n",
       "                                ticket_classification  \n",
       "1                  Debt collection + Credit card debt  \n",
       "2   Credit card or prepaid card + General-purpose ...  \n",
       "10  Credit reporting, credit repair services, or o...  \n",
       "11  Credit reporting, credit repair services, or o...  \n",
       "14     Checking or savings account + Checking account  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checamos que todo haya salido bien\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bank account or service + (CD) Certificate of deposit',\n",
       " 'Bank account or service + Cashing a check without an account',\n",
       " 'Bank account or service + Checking account',\n",
       " 'Bank account or service + Other bank product/service',\n",
       " 'Bank account or service + Savings account',\n",
       " 'Checking or savings account + CD (Certificate of Deposit)',\n",
       " 'Checking or savings account + Checking account',\n",
       " 'Checking or savings account + Other banking product or service',\n",
       " 'Checking or savings account + Personal line of credit',\n",
       " 'Checking or savings account + Savings account',\n",
       " 'Consumer Loan + Installment loan',\n",
       " 'Consumer Loan + Pawn loan',\n",
       " 'Consumer Loan + Title loan',\n",
       " 'Consumer Loan + Vehicle lease',\n",
       " 'Consumer Loan + Vehicle loan',\n",
       " 'Credit card or prepaid card + General-purpose credit card or charge card',\n",
       " 'Credit card or prepaid card + General-purpose prepaid card',\n",
       " 'Credit card or prepaid card + Gift card',\n",
       " 'Credit card or prepaid card + Government benefit card',\n",
       " 'Credit card or prepaid card + Payroll card',\n",
       " 'Credit card or prepaid card + Store credit card',\n",
       " 'Credit reporting, credit repair services, or other personal consumer reports + Credit repair services',\n",
       " 'Credit reporting, credit repair services, or other personal consumer reports + Credit reporting',\n",
       " 'Credit reporting, credit repair services, or other personal consumer reports + Other personal consumer report',\n",
       " 'Debt collection + Auto',\n",
       " 'Debt collection + Auto debt',\n",
       " 'Debt collection + Credit card',\n",
       " 'Debt collection + Credit card debt',\n",
       " 'Debt collection + Federal student loan',\n",
       " 'Debt collection + I do not know',\n",
       " 'Debt collection + Mortgage',\n",
       " 'Debt collection + Mortgage debt',\n",
       " 'Debt collection + Non-federal student loan',\n",
       " 'Debt collection + Other (i.e. phone, health club, etc.)',\n",
       " 'Debt collection + Other debt',\n",
       " 'Debt collection + Payday loan',\n",
       " 'Debt collection + Payday loan debt',\n",
       " 'Debt collection + Private student loan debt',\n",
       " 'Money transfer, virtual currency, or money service + Check cashing service',\n",
       " 'Money transfer, virtual currency, or money service + Debt settlement',\n",
       " 'Money transfer, virtual currency, or money service + Domestic (US) money transfer',\n",
       " 'Money transfer, virtual currency, or money service + Foreign currency exchange',\n",
       " 'Money transfer, virtual currency, or money service + International money transfer',\n",
       " 'Money transfer, virtual currency, or money service + Mobile or digital wallet',\n",
       " 'Money transfer, virtual currency, or money service + Money order',\n",
       " 'Money transfer, virtual currency, or money service + Refund anticipation check',\n",
       " \"Money transfer, virtual currency, or money service + Traveler's check or cashier's check\",\n",
       " 'Money transfer, virtual currency, or money service + Virtual currency',\n",
       " 'Money transfers + Domestic (US) money transfer',\n",
       " 'Money transfers + International money transfer',\n",
       " 'Mortgage + Conventional adjustable mortgage (ARM)',\n",
       " 'Mortgage + Conventional fixed mortgage',\n",
       " 'Mortgage + Conventional home mortgage',\n",
       " 'Mortgage + FHA mortgage',\n",
       " 'Mortgage + Home equity loan or line of credit',\n",
       " 'Mortgage + Home equity loan or line of credit (HELOC)',\n",
       " 'Mortgage + Other mortgage',\n",
       " 'Mortgage + Other type of mortgage',\n",
       " 'Mortgage + Reverse mortgage',\n",
       " 'Mortgage + VA mortgage',\n",
       " 'Other financial service + Check cashing',\n",
       " 'Other financial service + Foreign currency exchange',\n",
       " 'Other financial service + Money order',\n",
       " 'Other financial service + Traveler’s/Cashier’s checks',\n",
       " 'Payday loan, title loan, or personal loan + Installment loan',\n",
       " 'Payday loan, title loan, or personal loan + Payday loan',\n",
       " 'Payday loan, title loan, or personal loan + Personal line of credit',\n",
       " 'Payday loan, title loan, or personal loan + Title loan',\n",
       " 'Prepaid card + Electronic Benefit Transfer / EBT card',\n",
       " 'Prepaid card + General purpose card',\n",
       " 'Prepaid card + Gift or merchant card',\n",
       " 'Prepaid card + Government benefit payment card',\n",
       " 'Prepaid card + Other special purpose card',\n",
       " 'Student loan + Federal student loan servicing',\n",
       " 'Student loan + Non-federal student loan',\n",
       " 'Student loan + Private student loan',\n",
       " 'Vehicle loan or lease + Lease',\n",
       " 'Vehicle loan or lease + Loan']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checamos si hay errores gramaticales o pares de categorías para lo mismo\n",
    "sorted(df.ticket_classification.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos en el directorio de data transformada\n",
    "df.to_csv('../data/transformed_data/preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a eliminar las palabras cuya frecuencia sobrepase el treshold, ya que existen palabras que se repiten mucho y no son precisamente stopwords, en especial chase, jp, y otros términos del banco que son casi constantes, por lo que no representan nada para el modelo y es mejor eliminarlas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def delete_frequent_words(corpus, threshold=0.75):\n",
    "    # Creamos un CountVectorizer para obtener el conteo \n",
    "    vectorizer = CountVectorizer(stop_words='english')\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    # Obtener la frecuencia de cada palabra\n",
    "    word_counts = X.sum(axis=0).A1  #Convertimos en un array unidimensional\n",
    "    word_list = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    # Calculamos el treshold en base al porcentaje y el tamaño del df\n",
    "    threshold_count = len(corpus) * threshold\n",
    "    \n",
    "    # Obtenemos las palabras que superen el treshold\n",
    "    frequent_words = {word_list[i] for i, count in enumerate(word_counts) if count > threshold_count}\n",
    "    \n",
    "    \n",
    "    filtered_corpus = []\n",
    "    for doc in corpus:\n",
    "        # Eliminamos esas palabras del corpus\n",
    "        filtered_doc = ' '.join([word for word in doc.split() if word not in frequent_words])\n",
    "        filtered_corpus.append(filtered_doc)\n",
    "    \n",
    "    return filtered_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aquí vamos a hacer una pequeña limpieza, estirando contracciones a su forma base, convertir a minúsculas, eliminar todos los caracteres no alfanuméricos, las censuras y por último los stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpiamos otras cosillas con regex descontraemos y quitamos stopwords\n",
    "def clean_complaint(complaint):\n",
    "\n",
    "    #Convertimos a minúsculas\n",
    "    complaint = complaint.lower()\n",
    "\n",
    "    #Descontraemos\n",
    "    complaint = contractions.fix(complaint)\n",
    "\n",
    "    #Quitamos donde haya dos o más x\n",
    "    complaint = re.sub(r'xx+', '', complaint)\n",
    "    \n",
    "    #Eliminar números\n",
    "    #complaint = re.sub(r'\\d', '', complaint)\n",
    "\n",
    "    #Dejamos sólo alfanuméricos\n",
    "    complaint = re.sub(r'\\W', ' ', complaint)\n",
    "\n",
    "    # Tokenizamos y quitamos stopwords\n",
    "    complaint_tokens = word_tokenize(complaint)\n",
    "    complaint = ' '.join([word for word in complaint_tokens if word not in stop_words])\n",
    "\n",
    "    return complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesamiento por batches\n",
    "batch_size = 1000\n",
    "cleaned_corpus = []\n",
    "\n",
    "for start in range(0, len(df), batch_size):\n",
    "    end = start + batch_size\n",
    "    batch_complaints = df['complaint_what_happened'][start:end]\n",
    "    \n",
    "    # Limpiar cada complaint en cada batch\n",
    "    cleaned_batch = batch_complaints.apply(clean_complaint)\n",
    "    \n",
    "    # Appendear a la lista\n",
    "    cleaned_corpus.extend(cleaned_batch)\n",
    "\n",
    "cleaned_corpus = delete_frequent_words(cleaned_corpus, threshold=0.80)\n",
    "\n",
    "# Actualizar el df\n",
    "df['complaint_what_happened'] = cleaned_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>ticket_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good morning name appreciate could help put st...</td>\n",
       "      <td>Debt collection + Credit card debt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>upgraded 2018 told agent upgrade anniversary d...</td>\n",
       "      <td>Credit card or prepaid card + General-purpose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>reported 2019 however fraudulent application s...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018 trying book ticket came across offer 300 ...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>grand son give check 1600 deposit fund clear c...</td>\n",
       "      <td>Checking or savings account + Checking account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              complaint_what_happened  \\\n",
       "1   good morning name appreciate could help put st...   \n",
       "2   upgraded 2018 told agent upgrade anniversary d...   \n",
       "10  reported 2019 however fraudulent application s...   \n",
       "11  2018 trying book ticket came across offer 300 ...   \n",
       "14  grand son give check 1600 deposit fund clear c...   \n",
       "\n",
       "                                ticket_classification  \n",
       "1                  Debt collection + Credit card debt  \n",
       "2   Credit card or prepaid card + General-purpose ...  \n",
       "10  Credit reporting, credit repair services, or o...  \n",
       "11  Credit reporting, credit repair services, or o...  \n",
       "14     Checking or savings account + Checking account  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checamos que todo esté en orden\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos el treshold de rows mínimos por categoría, véase el EDA\n",
    "counts = df['ticket_classification'].value_counts()\n",
    "todelete = counts[counts < 10]\n",
    "df = df[~df['ticket_classification'].isin(todelete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/clean_data/cleaned_corpus.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
