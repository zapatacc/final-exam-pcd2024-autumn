{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import  root_mean_squared_error\n",
    "from sklearn.feature_extraction import  DictVectorizer\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_what_happened</th>\n",
       "      <th>ticket_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good morning name appreciate could help put st...</td>\n",
       "      <td>Debt collection + Credit card debt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>upgraded 2018 told agent upgrade anniversary d...</td>\n",
       "      <td>Credit card or prepaid card + General-purpose ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reported 2019 however fraudulent application s...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018 trying book ticket came across offer 300 ...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grand son give check 1600 deposit fund clear c...</td>\n",
       "      <td>Checking or savings account + Checking account</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             complaint_what_happened  \\\n",
       "0  good morning name appreciate could help put st...   \n",
       "1  upgraded 2018 told agent upgrade anniversary d...   \n",
       "2  reported 2019 however fraudulent application s...   \n",
       "3  2018 trying book ticket came across offer 300 ...   \n",
       "4  grand son give check 1600 deposit fund clear c...   \n",
       "\n",
       "                               ticket_classification  \n",
       "0                 Debt collection + Credit card debt  \n",
       "1  Credit card or prepaid card + General-purpose ...  \n",
       "2  Credit reporting, credit repair services, or o...  \n",
       "3  Credit reporting, credit repair services, or o...  \n",
       "4     Checking or savings account + Checking account  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/clean_data/cleaned_corpus.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target y predictor\n",
    "X = df['complaint_what_happened']\n",
    "y = df['ticket_classification']\n",
    "\n",
    "# Mapear categor√≠as\n",
    "category_mapping = {category: index for index, category in enumerate(y.unique())}\n",
    "y_mapped = y.map(category_mapping)\n",
    "y = y_mapped.tolist()\n",
    "label_names = list(category_mapping.keys())\n",
    "labels_list = list(category_mapping.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizamos usando TFIDF\n",
    "vectorizer = TfidfVectorizer(stop_words = stopwords.words('english'))\n",
    "X_TF = vectorizer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pepechuy/Downloads/School/Lab5/Examen/final-exam-pcd2024-autumn/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tfid\n",
    "text_train, text_test, sent_train, sent_test = train_test_split(X_TF, y, test_size = 0.20, random_state = 309)\n",
    "\n",
    "#Param grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1],  # Regularization strength (note the capital 'C')\n",
    "    #'solver': ['lbfgs', 'liblinear'],  # Solvers for Logistic Regression\n",
    "    'penalty': ['l2', 'elasticnet'],  # Penalty type ('l2' is standard for solvers like 'lbfgs' and 'liblinear')\n",
    "    'max_iter': [100, 200]  # Number of iterations\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(random_state=309),\n",
    "    param_grid,\n",
    "    cv=3,  # 5-fold cross-validation\n",
    "    scoring='accuracy',  # Metric to optimize\n",
    "    n_jobs=2,\n",
    "    verbose=2  # Higher verbosity for detailed output\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "grid_search.fit(text_train, sent_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Predictions and evaluation\n",
    "sent_pred = best_model.predict(text_test)\n",
    "cm = confusion_matrix(sent_test, sent_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Classification Report:\\n\", classification_report(sent_test, sent_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.571579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Classification Error</td>\n",
       "      <td>0.428421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.189042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.102761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.113318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric     Value\n",
       "0              Accuracy  0.571579\n",
       "1  Classification Error  0.428421\n",
       "2             Precision  0.189042\n",
       "3                Recall  0.102761\n",
       "4              F1-score  0.113318"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#METRICS\n",
    "def auto_metrics_multiclass(sent_test, sent_pred):\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(sent_test, sent_pred)\n",
    "    \n",
    "    # Classification error\n",
    "    classification_error = 1 - accuracy\n",
    "    \n",
    "    # Precision, Recall, F1 (for multiclass use macro, micro, or weighted, with zero_division handling)\n",
    "    precision = precision_score(sent_test, sent_pred, average='macro', zero_division=0)\n",
    "    recall = recall_score(sent_test, sent_pred, average='macro', zero_division=0)\n",
    "    f1 = f1_score(sent_test, sent_pred, average='macro', zero_division=0)\n",
    "\n",
    "    # Table with metrics\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Classification Error', 'Precision', 'Recall', 'F1-score'],\n",
    "        'Value': [accuracy, classification_error, precision, recall, f1]\n",
    "    })\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "logistic_metrics = auto_metrics_multiclass(sent_test, sent_pred)\n",
    "logistic_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 2000, stop_words = stopwords.words('english'))\n",
    "X_TF = vectorizer.fit_transform(corpus).toarray()\n",
    "\n",
    "\n",
    "#Train Split\n",
    "X_list = corpus\n",
    "y = df_corpus['category']\n",
    "\n",
    "\n",
    "# Map categories into integers\n",
    "category_mapping = {category: index for index, category in enumerate(y.unique())}\n",
    "y_mapped = y.map(category_mapping)\n",
    "y = y_mapped.tolist()\n",
    "label_names = list(category_mapping.keys())\n",
    "labels_list = list(category_mapping.values())\n",
    "\n",
    "# Tfid\n",
    "text_train, text_test, sent_train, sent_test = train_test_split(X_TF, y, test_size = 0.20, random_state = 309)\n",
    "\n",
    "# Training the Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=309)\n",
    "rf_classifier.fit(text_train, sent_train)\n",
    "\n",
    "# Predicts\n",
    "sent_pred = rf_classifier.predict(text_test)\n",
    "\n",
    "# Making the confusion matrix\n",
    "cm = confusion_matrix(sent_test, sent_pred)\n",
    "\n",
    "# Make the classes on the predictions\n",
    "unique_classes = sorted(set(sent_test).union(set(sent_pred)))\n",
    "\n",
    "# Map class labels to the unique classes\n",
    "class_labels = [labels_list[i] for i in unique_classes]\n",
    "class_names = [label_names[i] for i in unique_classes]\n",
    "\n",
    "# for labels to match the confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "cm_display.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "ax.set_xticklabels(class_names, rotation=90)\n",
    "ax.set_yticklabels(class_names, rotation=0)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
