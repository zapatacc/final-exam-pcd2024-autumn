{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primero en local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genera los runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iosoypato/Documents/ITESO/CienciaDatos/EXAMENFINAL/final-exam-pcd2024-autumn/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/iosoypato/Documents/ITESO/CienciaDatos/EXAMENFINAL/final-exam-pcd2024-autumn/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/iosoypato/Documents/ITESO/CienciaDatos/EXAMENFINAL/final-exam-pcd2024-autumn/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/11/20 01:21:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression, Best Params: {'C': 10, 'penalty': 'l2'}, Accuracy: 0.5995364057812926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iosoypato/Documents/ITESO/CienciaDatos/EXAMENFINAL/final-exam-pcd2024-autumn/.venv/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Carga el dataset\n",
    "df = pd.read_csv(\"../data/clean_data/cleaned.csv\")\n",
    "\n",
    "# Define X e y\n",
    "X = df['complaint_what_happened']\n",
    "y = df['ticket_classification']\n",
    "\n",
    "# Codifica las clases de `y` como valores enteros\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.4, random_state=17, stratify=y_encoded\n",
    ")\n",
    "\n",
    "train_classes = set(y_train)\n",
    "valid_indices = [i for i, label in enumerate(y_test) if label in train_classes]\n",
    "\n",
    "if len(valid_indices) < len(y_test):\n",
    "    print(f\"Filtrando {len(y_test) - len(valid_indices)} instancias de prueba con clases desconocidas.\")\n",
    "X_test = X_test.iloc[valid_indices]\n",
    "y_test = y_test[valid_indices]\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Configura el tracking de MLflow local\n",
    "mlflow.set_tracking_uri(\"file:///tmp/mlruns\")\n",
    "mlflow.set_experiment(\"patricio-villanueva-experiments\")\n",
    "\n",
    "# Define modelos y parámetros para GridSearch\n",
    "models_and_params = {\n",
    "    \"Logistic Regression\": (LogisticRegression(max_iter=1000), {\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"penalty\": [\"l2\"]\n",
    "    }),\n",
    "    \"Random Forest\": (RandomForestClassifier(), {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [None, 10, 20],\n",
    "        \"min_samples_split\": [2, 5],\n",
    "        \"min_samples_leaf\": [1, 2]\n",
    "    })\n",
    "    # \"XGBoost\": (XGBClassifier(use_label_encoder=False, eval_metric='logloss'), {\n",
    "    #     \"n_estimators\": [100, 200],\n",
    "    #     \"max_depth\": [3, 6],\n",
    "    #     \"learning_rate\": [0.01, 0.1],\n",
    "    #     \"subsample\": [0.8, 1.0]\n",
    "    # })\n",
    "}\n",
    "\n",
    "# Entrenamiento y logging en MLflow\n",
    "for model_name, (model, params) in models_and_params.items():\n",
    "    grid_search = GridSearchCV(model, params, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"GridSearch - {model_name}\"):\n",
    "        # Entrena el modelo usando GridSearchCV\n",
    "        grid_search.fit(X_train_tfidf, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test_tfidf)\n",
    "\n",
    "        # Calcula métricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        # Loggea parámetros y métricas del mejor modelo\n",
    "        mlflow.log_params(grid_search.best_params_)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", report[\"weighted avg\"][\"precision\"])\n",
    "        mlflow.log_metric(\"recall\", report[\"weighted avg\"][\"recall\"])\n",
    "        mlflow.log_metric(\"f1_score\", report[\"weighted avg\"][\"f1-score\"])\n",
    "        \n",
    "        # Loggea el modelo\n",
    "        mlflow.sklearn.log_model(best_model, artifact_path=f\"best_model_{model_name}\")\n",
    "\n",
    "        print(f\"Model: {model_name}, Best Params: {grid_search.best_params_}, Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecciona el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor run es: 40364ba68a9f4545a3fe6fe25ba05102 con accuracy: 0.5825960649676483\n",
      "El modelo ha sido registrado como 'patricio-model' con alias 'champion' y etapa 'Production'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'patricio-model'.\n",
      "Created version '1' of model 'patricio-model'.\n",
      "/tmp/ipykernel_22094/1565425304.py:48: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  model_version = client.get_latest_versions(name=model_name, stages=[\"None\"])[0].version\n",
      "/tmp/ipykernel_22094/1565425304.py:56: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:///tmp/mlruns\") \n",
    "\n",
    "# Nombre del experimento\n",
    "experiment_name = \"patricio-villanueva-experiments\"\n",
    "client = MlflowClient() \n",
    "\n",
    "# Id del experimento\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    raise ValueError(f\"No se encontró el experimento con nombre: {experiment_name}\")\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Todos los runs (bueno los ultimos 1000)\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"\",\n",
    "    run_view_type=mlflow.entities.ViewType.ACTIVE_ONLY,\n",
    "    max_results=1000\n",
    ")\n",
    "\n",
    "# Encuentra el run con la mejor accuracy se que hay un order by pero neta nunca me sale asi que a la antigua\n",
    "best_run = None\n",
    "best_accuracy = -float(\"inf\")\n",
    "\n",
    "for run in runs:\n",
    "    metrics = run.data.metrics\n",
    "    if \"accuracy\" in metrics and metrics[\"accuracy\"] > best_accuracy:\n",
    "        best_accuracy = metrics[\"accuracy\"]\n",
    "        best_run = run\n",
    "\n",
    "if best_run is None:\n",
    "    raise ValueError(\"No se encontraron runs con la métrica 'accuracy'.\")\n",
    "\n",
    "# Log del mejor run\n",
    "print(f\"El mejor run es: {best_run.info.run_id} con accuracy: {best_accuracy}\")\n",
    "\n",
    "# Registra el modelo del mejor run\n",
    "model_uri = f\"runs:/{best_run.info.run_id}/model\"\n",
    "model_name = \"patricio-model\"\n",
    "\n",
    "# Registra el modelo en MLflow Model Registry\n",
    "registered_model = mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "# Agrega un alias \"champion\" al modelo registrado\n",
    "model_version = client.get_latest_versions(name=model_name, stages=[\"None\"])[0].version\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=\"champion\",\n",
    "    version=model_version\n",
    ")\n",
    "\n",
    "# Transiciona el modelo a la etapa \"Production\"\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True  \n",
    ")\n",
    "\n",
    "print(f\"El modelo ha sido registrado como '{model_name}' con alias 'champion' y etapa 'Production'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En dagshub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "\n",
    "# Configuración para DagsHub\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/<usuario>/<repo>.mlflow\")\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"<tu_usuario>\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"<tu_token>\"\n",
    "\n",
    "df = pd.read_csv(\"../data/clean_data/cleaned.csv\")\n",
    "\n",
    "# Define X y y\n",
    "X = df['complaint_what_happened']\n",
    "y = df['ticket_classification']\n",
    "\n",
    "# División en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorización de texto\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Configura el experimento en MLflow\n",
    "mlflow.set_experiment(\"ticket_classification_experiments\")\n",
    "\n",
    "# Define modelos a evaluar\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# Entrenamiento y logging en MLflow\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Entrena el modelo\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "        \n",
    "        # Calcula métricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        # Loggea los parámetros y métricas\n",
    "        mlflow.log_param(\"model_type\", model_name)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", report[\"weighted avg\"][\"precision\"])\n",
    "        mlflow.log_metric(\"recall\", report[\"weighted avg\"][\"recall\"])\n",
    "        mlflow.log_metric(\"f1_score\", report[\"weighted avg\"][\"f1-score\"])\n",
    "        \n",
    "        # Loggea el modelo\n",
    "        mlflow.sklearn.log_model(model, artifact_path=model_name)\n",
    "\n",
    "        print(f\"Model: {model_name}, Accuracy: {accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
