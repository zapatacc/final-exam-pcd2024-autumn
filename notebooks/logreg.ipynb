{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Training LogReg\n",
    "\n",
    "Para la selección de modelos, decidí entrenar un modelo de Linear Support Vector Machine y otro de Regresión Logística\n",
    "\n",
    "En este notebook se encuentra el entrenamiento de LogReg.\n",
    "\n",
    "A continuación, aplicaremos CountVectorizer y TF-IDF Transformer.\n",
    "\n",
    "CountVectorizer convierte el texto de cada registro a una matriz, en la cuál cada renglón representa un documento (que es un registro de la columna de quejas) y cada columna es una palabra del vocabulario del mismo.\n",
    "\n",
    "TF-IDF Transformer convierte el conteo de palabras a un score de TF-IDF, que normaliza la importancia de cada palabra basada en su frecuencia en cada documento y a través de todos los documentos. Nos ayuda a enfocarnos en las palabras más importantes, que no son tan comunes, pero sobre todo convierte el texto en formato numérico para poder entrenar nuestro modelo."
   ],
   "id": "8eb142f8b41d4521"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T21:48:11.389364Z",
     "start_time": "2024-11-21T21:48:11.324222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import dagshub\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from hyperopt import fmin, tpe, hp, Trials\n",
    "from hyperopt.pyll import scope\n",
    "import pickle\n",
    "import pathlib"
   ],
   "id": "941527d0832083a6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T21:48:11.688117Z",
     "start_time": "2024-11-21T21:48:11.394844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/processed.csv')\n",
    "X = df.complaint_what_happened\n",
    "y = df.ticket_classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ],
   "id": "95a524f88aaacd13",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T21:48:12.215698Z",
     "start_time": "2024-11-21T21:48:11.708383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dagshub.init(url=\"https://dagshub.com/zapatacc/final-exam-pcd2024-autumn\", mlflow=True)\n",
    "\n",
    "MLFLOW_TRACKING_URI = mlflow.get_tracking_uri()\n",
    "\n",
    "print(MLFLOW_TRACKING_URI)\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "mlflow.set_experiment(experiment_name=\"erick-machuca-logreg\")"
   ],
   "id": "9c5cd1dede44f6c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Initialized MLflow to track repo \u001B[32m\"zapatacc/final-exam-pcd2024-autumn\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"zapatacc/final-exam-pcd2024-autumn\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Repository zapatacc/final-exam-pcd2024-autumn initialized!\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository zapatacc/final-exam-pcd2024-autumn initialized!\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/2821e7ade72746f79102bef93a693c9e', creation_time=1732220751696, experiment_id='22', last_update_time=1732220751696, lifecycle_stage='active', name='erick-machuca-logreg', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T21:48:22.115069Z",
     "start_time": "2024-11-21T21:48:12.240294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start logging the experiment\n",
    "with mlflow.start_run() as run:\n",
    "    # Log model parameters\n",
    "    mlflow.log_param(\"n_jobs\", 1)\n",
    "    mlflow.log_param(\"C\", 1e5)\n",
    "    mlflow.log_param(\"max_iter\", 1000)\n",
    "    mlflow.log_param(\"class_weight\", \"balanced\")\n",
    "\n",
    "    # Define and train the logreg pipeline\n",
    "    logreg = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', LogisticRegression(n_jobs=1, C=1e5, max_iter=1000, class_weight='balanced', random_state=42)),\n",
    "    ])\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    # Calculate and log metrics\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    recall = recall_score(y_pred, y_test, average='macro')\n",
    "    precision = precision_score(y_pred, y_test, average='macro')\n",
    "    f1 = f1_score(y_pred, y_test, average='macro')\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "\n",
    "    # Print a success message\n",
    "    print(f\"logreg Classifier logged in MLflow with accuracy: {accuracy:.2f}, recall: {recall:.2f}, precision: {precision:.2f}, f1: {f1:.2f}\")"
   ],
   "id": "6b42d480f9c35ea8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg Classifier logged in MLflow with accuracy: 0.57, recall: 0.44, precision: 0.34, f1: 0.37\n",
      "🏃 View run likeable-chimp-38 at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/22/runs/dadab7041cca41fc936cd62ec8f8b057\n",
      "🧪 View experiment at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/22\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T21:49:27.723018Z",
     "start_time": "2024-11-21T21:48:22.138306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Define the objective function for Logistic Regression hyperparameter tuning\n",
    "def objective(params):\n",
    "    # Extract parameters from the search space\n",
    "    C = params['C']\n",
    "    max_iter = int(params['max_iter'])\n",
    "\n",
    "    # Build and train the Logistic Regression pipeline\n",
    "    logreg = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', LogisticRegression(\n",
    "            n_jobs=1,\n",
    "            C=C,\n",
    "            max_iter=max_iter,\n",
    "            class_weight='balanced',\n",
    "            random_state=42))\n",
    "    ])\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and calculate the objective metric (e.g., negative accuracy for minimization)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return -accuracy  # Return negative because fmin minimizes by default\n",
    "\n",
    "# 2. Set up the search space for hyperparameters\n",
    "search_space = {\n",
    "    'C': hp.loguniform('C', -3, 3),  # Regularization strength on a log scale\n",
    "    'max_iter': scope.int(hp.quniform('max_iter', 100, 1000, 100))  # Number of iterations\n",
    "}\n",
    "\n",
    "# 3. Start MLflow run for hyperparameter optimization\n",
    "with mlflow.start_run(run_name=\"LogReg Hyper-parameter Optimization\", nested=True):\n",
    "    # 4. Optimize Logistic Regression parameters using hyperopt\n",
    "    trials = Trials()\n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=30,  # Adjust for more evaluations\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # Convert parameters to usable types\n",
    "    best_params['C'] = float(best_params['C'])\n",
    "    best_params['max_iter'] = int(best_params['max_iter'])\n",
    "\n",
    "    # Log the best parameters to MLflow\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # 5. Set experiment tags for tracking\n",
    "    mlflow.set_tags({\n",
    "        \"project\": \"Text Classification with Logistic Regression\",\n",
    "        \"optimizer_engine\": \"hyper-opt\",\n",
    "        \"model_family\": \"Logistic Regression\",\n",
    "        \"feature_set_version\": 1,\n",
    "    })\n",
    "\n",
    "    # 6. Train the Logistic Regression model with the best parameters\n",
    "    logreg = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', LogisticRegression(\n",
    "            n_jobs=1,\n",
    "            C=best_params['C'],\n",
    "            max_iter=best_params['max_iter'],\n",
    "            class_weight='balanced',\n",
    "            random_state=42))\n",
    "    ])\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions and calculate metrics\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    # Log metrics to MLflow\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"f1\", f1)\n",
    "\n",
    "    # 7. Save the trained Logistic Regression pipeline using mlflow.sklearn\n",
    "    mlflow.sklearn.log_model(logreg, \"model\")\n",
    "\n",
    "    # Print out a success message\n",
    "    print(f\"Best Logistic Regression model logged with accuracy: {accuracy:.2f}, recall: {recall:.2f}, precision: {precision:.2f}, f1: {f1:.2f}\")\n"
   ],
   "id": "4e98d9aee0fe8917",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:46<00:00,  4.66s/trial, best loss: -0.5900308036964436]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 15:49:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression model logged with accuracy: 0.59, recall: 0.41, precision: 0.42, f1: 0.41\n",
      "🏃 View run LogReg Hyper-parameter Optimization at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/22/runs/52802434a1024c37bae0e0fb8f8ec50a\n",
      "🧪 View experiment at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/22\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
