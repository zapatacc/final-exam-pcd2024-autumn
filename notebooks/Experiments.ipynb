{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/clean_data/cleaned_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Target y predictor\n",
    "X = df['complaint_what_happened']\n",
    "y = df['ticket_classification']\n",
    "\n",
    "# Mapear categor√≠as\n",
    "labelmapping = LabelEncoder()\n",
    "y_encoded = labelmapping.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Vectorizamos usando TFIDF\n",
    "vectorizer = TfidfVectorizer(stop_words = stopwords.words('english'))\n",
    "X_TF = vectorizer.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"zapatacc/final-exam-pcd2024-autumn\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"zapatacc/final-exam-pcd2024-autumn\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository zapatacc/final-exam-pcd2024-autumn initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository zapatacc/final-exam-pcd2024-autumn initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/4b1db8acf1e34ea9af430f57180ec8de', creation_time=1732170344340, experiment_id='17', last_update_time=1732170344340, lifecycle_stage='active', name='jesus-carbajal-logreg-label-encoder', tags={}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "\n",
    "dagshub.init(repo_owner='zapatacc', repo_name='final-exam-pcd2024-autumn', mlflow=True)\n",
    "mlflow.set_experiment(\"jesus-carbajal-logreg-label-encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pepechuy/Downloads/School/Lab5/Examen/final-exam-pcd2024-autumn/.venv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/pepechuy/Downloads/School/Lab5/Examen/final-exam-pcd2024-autumn/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/pepechuy/Downloads/School/Lab5/Examen/final-exam-pcd2024-autumn/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/pepechuy/Downloads/School/Lab5/Examen/final-exam-pcd2024-autumn/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024/11/21 00:51:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run Logreg Pipeline at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/17/runs/8ccf9f0120494d78a04c99aa0b113d82\n",
      "üß™ View experiment at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/17\n"
     ]
    }
   ],
   "source": [
    "# Tfid\n",
    "text_train, text_test, sent_train, sent_test = train_test_split(X, y, test_size=0.20, random_state=309)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"vectorizer\", TfidfVectorizer()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=500))\n",
    "])\n",
    "\n",
    "params_grid = {\n",
    "    'logreg__C': [0.01, 0.1, 1],\n",
    "    'logreg__penalty': ['l2'],\n",
    "    'logreg__solver': ['lbfgs'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, params_grid, scoring='accuracy', cv=5, n_jobs=1, verbose=1)\n",
    "\n",
    "with mlflow.start_run(run_name=\"Logreg Pipeline\"):\n",
    "    grid_search.fit(text_train, sent_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    y_pred = best_model.predict(text_test)\n",
    "    \n",
    "    # calcular m√©tricas\n",
    "    accuracy = accuracy_score(sent_test, y_pred)\n",
    "    report = classification_report(sent_test, y_pred, output_dict=True)\n",
    "    \n",
    "    # Loggear el mejor modelo\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", report[\"weighted avg\"][\"precision\"])\n",
    "    mlflow.log_metric(\"recall\", report[\"weighted avg\"][\"recall\"])\n",
    "    mlflow.log_metric(\"f1_score\", report[\"weighted avg\"][\"f1-score\"])\n",
    "    \n",
    "    mlflow.sklearn.log_model(best_model, artifact_path=\"pipeline_model\")\n",
    "\n",
    "    with open(\"labelmapping.pkl\", \"wb\") as f:\n",
    "        pickle.dump(labelmapping, f)\n",
    "    mlflow.log_artifact(\"labelmapping.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
