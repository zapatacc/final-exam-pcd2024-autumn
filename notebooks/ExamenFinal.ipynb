{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "      ___   _\n",
    "     |_ _| | |_    ___   ___    ___\n",
    "      | |  | __|  / _ \\ / __|  / _ \\\n",
    "      | |  | |_  |  __/ \\__ \\ | (_) |\n",
    "     |___|  \\__|  \\___| |___/  \\___/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "<h1><strong>Classification Challenge: Mejorando la Gestión de Quejas con Machine Learning</strong></h1>\n",
    "\n",
    "<hr>\n",
    "<p>Bienvenid@ al Classification Challenge</p>\n",
    "<h2>Descripción</h2>\n",
    "\n",
    "<p>En el ámbito corporativo, enfrentar y resolver desafíos diarios es esencial para mejorar la experiencia del cliente y optimizar las operaciones. Un desafío común es la adecuada gestión y clasificación de las quejas de los clientes. Para abordar esta problemática de manera efectiva, disponemos de un dataset inicial que será empleado para entrenar un modelo de machine learning. Este modelo tiene como objetivo predecir la categoría adecuada para cada nueva queja recibida, utilizando el conocimiento derivado de casos anteriores.\n",
    "\n",
    "Es importante mencionar que el dataset proporcionado, denominado `tickets_classification_eng.json` (Puedes encontrar este dataset en la carpeta `data/raw_data`), no está limpio y requerirá un proceso de preparación antes de ser utilizado para el entrenamiento del modelo. Este dataset final deberá está formado por las siguientes columnas:\n",
    "\n",
    "    complaint_what_happened - El contenido textual de la queja, que proporciona detalles sobre el incidente o problema experimentado por el cliente.\n",
    "    ticket_classification - Una combinación de las categorías de producto y subproducto involucradas, que clasifica la queja en un contexto más amplio.\n",
    "\n",
    "Para asegurarnos de que el dataset esté listo para su uso, es crucial seguir los procedimientos que se expondran adelante para seleccionar, limpiar y preparar adecuadamente los datos. Una vez que se haya completado este proceso, será necesario guardar el dataset limpio para asegurar que el modelo de machine learning pueda ser entrenado con datos precisos y confiables. \n",
    "\n",
    "La implementación de este proyecto no solo busca mejorar la eficiencia en la gestión de quejas, sino también permitir que la empresa comprenda mejor las tendencias de los problemas reportados por los clientes, facilitando una respuesta más rápida y adecuada en el futuro.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "## Hints\n",
    "- Utilice la función `json_normalize` del paquete `pandas` [aqui](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) para importar los datos.\n",
    "- Use este código para importar el json como diccionario en `Python`:\n",
    "````\n",
    "import json\n",
    "with open(file_path, \"r\") as file:  \n",
    "    datos = json.load(file)\n",
    "````\n",
    "- Para la transformación de datos y obtener el dataset final a trabajar ejecute los comandos de pandas necesarios para aplicar el siguiente procedimiento:\n",
    "\n",
    "    1. **Selección de Columnas**:\n",
    "       Empieza seleccionando solo las columnas que contienen la información de la queja, el producto y el subproducto. Las columnas son:\n",
    "       - `_source.complaint_what_happened`\n",
    "       - `_source.product`\n",
    "       - `_source.sub_product`\n",
    "\n",
    "    2. **Renombrar Columnas**:\n",
    "       Cambia el nombre de las columnas para que sean más claras y fáciles de manejar:\n",
    "       - `_source.complaint_what_happened` a `complaint_what_happened`\n",
    "       - `_source.product` a `category`\n",
    "       - `_source.sub_product` a `sub_product`\n",
    "\n",
    "    3. **Creación de Nueva Columna**:\n",
    "       Añade una nueva columna llamada `ticket_classification` que sea el resultado de concatenar los valores de las columnas `category` y `sub_product`, separados por un signo más. Por ejemplo, si `category` contiene \"Banco\" y `sub_product` contiene \"Cuenta Corriente\", entonces `ticket_classification` debería ser \"Banco + Cuenta Corriente\".\n",
    "    \n",
    "    4. **Eliminar Columnas Redundantes**:\n",
    "       Después de crear la columna `ticket_classification`, elimina las columnas `sub_product` y `category`, ya que su información ahora está encapsulada en la nueva columna.\n",
    "    \n",
    "    5. **Limpieza de Datos en Columnas Específicas**:\n",
    "       Asegúrate de que la columna `complaint_what_happened` no contenga campos vacíos. Reemplaza esos campos vacíos con un valor que indique que los datos están ausentes (como `NaN`).\n",
    "    \n",
    "    6. **Eliminación de Filas con Datos Faltantes**:\n",
    "       Elimina todas las filas que tengan datos faltantes en las columnas críticas, es decir, `complaint_what_happened` y `ticket_classification`.\n",
    "    \n",
    "    7. **Reiniciar Índice**:\n",
    "       Finalmente, reinicia el índice del dataframe para asegurarte de que los índices sean consecutivos, lo cual es útil después de eliminar filas para mantener la consistencia y facilidad de acceso por índice.\n",
    "    8. **Guardar el DataFrame en un Archivo CSV**:\n",
    "   Guarda el DataFrame transformado en un archivo CSV. Elige un nombre de archivo que refleje el contenido del DataFrame y decide la ubicación más adecuada para guardar el archivo. Asegúrate de establecer el parámetro para no guardar el índice si no es necesario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './raw_data/tickets_classification_eng.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./raw_data/tickets_classification_eng.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m     datos \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Convertir el JSON a un DataFrame de pandas\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ITESO/5to_SEMESTRE/Proyecto_de_Ciencia_de_Datos/final-exam-pcd2024-autumn/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './raw_data/tickets_classification_eng.json'"
     ]
    }
   ],
   "source": [
    "file_path = './raw_data/tickets_classification_eng.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    datos = json.load(file)\n",
    "\n",
    "# Convertir el JSON a un DataFrame de pandas\n",
    "df = pd.json_normalize(datos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['_source.complaint_what_happened', '_source.product', '_source.sub_product']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    '_source.complaint_what_happened': 'complaint_what_happened',\n",
    "    '_source.product': 'category',\n",
    "    '_source.sub_product': 'sub_product'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ticket_classification'] = df['category'] + ' + ' + df['sub_product']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['category', 'sub_product'], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zq/qf312yqs5wnb29fvj3txfrqm0000gn/T/ipykernel_67948/857690592.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['complaint_what_happened'].replace('', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['complaint_what_happened'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['complaint_what_happened', 'ticket_classification'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./raw_data/cl_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_csv('./raw_data/cl_dataset.csv', index=False)\n",
    "df.head()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
