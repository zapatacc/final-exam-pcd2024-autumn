{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFLOW - Colom칠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import mlflow.sklearn\n",
    "from mlflow import log_metric, log_param\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import dagshub\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/cleaned_tickets.csv\")\n",
    "\n",
    "# Definir X e y\n",
    "X_raw = data['complaint_what_happened']  # Caracter칤stica textual\n",
    "y = data['ticket_classification']       # Variable objetivo\n",
    "\n",
    "# Vectorizar los textos (Transformaci칩n de texto a n칰meros)\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)  # Puedes ajustar los par치metros\n",
    "X = vectorizer.fit_transform(X_raw).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as colome8\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as colome8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"zapatacc/final-exam-pcd2024-autumn\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"zapatacc/final-exam-pcd2024-autumn\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository zapatacc/final-exam-pcd2024-autumn initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository zapatacc/final-exam-pcd2024-autumn initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dagshub.init(repo_owner='zapatacc', repo_name='final-exam-pcd2024-autumn', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/ff62fd7bba484e129f79990a7cada3e8', creation_time=1732145485355, experiment_id='4', last_update_time=1732145485355, lifecycle_stage='active', name='colome-experiment', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow\") \n",
    "mlflow.set_experiment(\"colome-experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 13:41:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo registrado con precisi칩n: 0.48589506986554176\n",
      "游끢 View run RandomForest-colome at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/4/runs/8565de4d4a6d4ff4a1fbba3a6cb2ad61\n",
      "游빍 View experiment at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "# Datos de ejemplo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Configuraci칩n del experimento\n",
    "mlflow.set_experiment(\"colome-experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest-colome\"):\n",
    "    # Hiperpar치metros\n",
    "    params = {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 10,\n",
    "        \"min_samples_split\": 2,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    # Registrar par치metros en MLflow\n",
    "    for param, value in params.items():\n",
    "        log_param(param, value)\n",
    "\n",
    "    # Entrenamiento del modelo\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicci칩n\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Evaluaci칩n\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Registrar el modelo\n",
    "    mlflow.sklearn.log_model(model, \"colome-random-forest-model\")\n",
    "\n",
    "    print(f\"Modelo registrado con precisi칩n: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- logistic regression log -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 13:42:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo registrado con precisi칩n: 0.5713155813340364\n",
      "游끢 View run LogisticRegression-colome at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/4/runs/e80bc3b1a19847ee8eb722c3dc84e35c\n",
      "游빍 View experiment at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"colome-experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"LogisticRegression-colome\"):\n",
    "    # Hiperpar치metros\n",
    "    params = {\n",
    "        \"C\": 1.0,  # Regularizaci칩n\n",
    "        \"solver\": \"liblinear\"  \n",
    "    }\n",
    "\n",
    "    # Registrar par치metros en MLflow\n",
    "    for param, value in params.items():\n",
    "        log_param(param, value)\n",
    "\n",
    "    # Crear el modelo de Regresi칩n Log칤stica\n",
    "    model = LogisticRegression(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predicci칩n\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Evaluaci칩n\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Registrar el modelo\n",
    "    mlflow.sklearn.log_model(model, \"logistic-regression-model\")\n",
    "\n",
    "    print(f\"Modelo registrado con precisi칩n: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\colom\\OneDrive - ITESO\\iteso\\5to semestre\\cienciadatos\\final-exam-pcd2024-autumn\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores par치metros: {'max_depth': 20, 'n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 13:46:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de Random Forest registrado con precisi칩n: 0.533350909570261\n",
      "游끢 View run RandomForest-colome-gridsearch at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/4/runs/93c8f38a097a48ec96796cdec40b43d2\n",
      "游빍 View experiment at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlflow.set_experiment(\"colome-experiment\")  # Configurar el experimento\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest-colome-gridsearch\"):  # Crear una nueva ejecuci칩n\n",
    "    # Definir los par치metros para GridSearch\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [5, 10, 20]\n",
    "    }\n",
    "\n",
    "    # Crear el modelo y realizar la b칰squeda de hiperpar치metros\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Obtener el mejor modelo y los par치metros 칩ptimos\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Loggear los mejores par치metros\n",
    "    print(f\"Mejores par치metros: {best_params}\")\n",
    "    for param, value in best_params.items():\n",
    "        mlflow.log_param(param, value)\n",
    "\n",
    "    # Evaluar el mejor modelo\n",
    "    accuracy = accuracy_score(y_test, best_model.predict(X_test))\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Registrar el modelo en MLflow\n",
    "    mlflow.sklearn.log_model(best_model, \"colome-gridsearch-random-forest\")\n",
    "\n",
    "    print(f\"Modelo de Random Forest registrado con precisi칩n: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\colom\\OneDrive - ITESO\\iteso\\5to semestre\\cienciadatos\\final-exam-pcd2024-autumn\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores par치metros: {'C': 1, 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 14:05:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de Regresi칩n Log칤stica registrado con precisi칩n: 0.5810703928288954\n",
      "游끢 View run LogisticRegression-colome-gridearch at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/4/runs/f1aec2099fdd465b9cdb10a91361727f\n",
      "游빍 View experiment at: https://dagshub.com/zapatacc/final-exam-pcd2024-autumn.mlflow/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"colome-experiment\")  # Configurar el experimento\n",
    "\n",
    "with mlflow.start_run(run_name=\"LogisticRegression-colome-gridearch\"):  # Crear una nueva ejecuci칩n\n",
    "    # Definir los par치metros de GridSearch para la Regresi칩n Log칤stica\n",
    "    param_grid_lr = {\n",
    "        'C': [0.01, 0.1, 1, 10],  # Par치metros de regularizaci칩n\n",
    "        'solver': ['liblinear', 'saga']  # Solvers disponibles\n",
    "    }\n",
    "\n",
    "    # Crear el modelo de Regresi칩n Log칤stica\n",
    "    logreg = LogisticRegression()\n",
    "\n",
    "    # Realizar la b칰squeda de hiperpar치metros con validaci칩n cruzada\n",
    "    grid_search_lr = GridSearchCV(logreg, param_grid_lr, cv=3, n_jobs=-1, verbose=1)\n",
    "    grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "    # Obtener el mejor modelo y los par치metros\n",
    "    best_lr_model = grid_search_lr.best_estimator_\n",
    "    best_lr_params = grid_search_lr.best_params_\n",
    "\n",
    "    # Loggear los mejores par치metros\n",
    "    print(f\"Mejores par치metros: {best_lr_params}\")\n",
    "    for param, value in best_lr_params.items():\n",
    "        mlflow.log_param(param, value)\n",
    "\n",
    "    # Evaluar el mejor modelo\n",
    "    predictions_lr = best_lr_model.predict(X_test)\n",
    "    accuracy_lr = accuracy_score(y_test, predictions_lr)\n",
    "\n",
    "    # Loggear la m칠trica de precisi칩n\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_lr)\n",
    "\n",
    "    # Registrar el modelo en MLflow\n",
    "    mlflow.sklearn.log_model(best_lr_model, \"colome-gridsearch-logistic-regression\")\n",
    "\n",
    "    print(f\"Modelo de Regresi칩n Log칤stica registrado con precisi칩n: {accuracy_lr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Champion y Challenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: f1aec2099fdd465b9cdb10a91361727f, Accuracy: 0.5810703928288954\n",
      "Run ID: e80bc3b1a19847ee8eb722c3dc84e35c, Accuracy: 0.5713155813340364\n",
      "Run ID: 93c8f38a097a48ec96796cdec40b43d2, Accuracy: 0.533350909570261\n",
      "Run ID: 8565de4d4a6d4ff4a1fbba3a6cb2ad61, Accuracy: 0.48589506986554176\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Nombre del experimento\n",
    "experiment_name = \"colome-experiment\"  # Ajusta el nombre si es diferente\n",
    "client = MlflowClient()\n",
    "\n",
    "# Obtener el ID del experimento\n",
    "experiment_id = client.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "# Buscar y ordenar las runs por accuracy\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[experiment_id],\n",
    "    filter_string=\"\",\n",
    "    order_by=[\"metrics.accuracy DESC\"],  # Ordenar por mayor accuracy\n",
    "    max_results=10  # Opcional: limitar el n칰mero de runs\n",
    ")\n",
    "\n",
    "# Verificar las mejores runs\n",
    "for run in runs:\n",
    "    print(f\"Run ID: {run.info.run_id}, Accuracy: {run.data.metrics['accuracy']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registrar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 14:08:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: colome-modelos, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registro de modelos 'colome-modelos' creado.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/21 14:08:49 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: colome-modelos, version 2\n",
      "C:\\Users\\colom\\AppData\\Local\\Temp\\ipykernel_13276\\3458228208.py:32: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n",
      "C:\\Users\\colom\\AppData\\Local\\Temp\\ipykernel_13276\\3458228208.py:40: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Champion: Run ID f1aec2099fdd465b9cdb10a91361727f, Accuracy: 0.5810703928288954\n",
      "Challenger: Run ID e80bc3b1a19847ee8eb722c3dc84e35c, Accuracy: 0.5713155813340364\n"
     ]
    }
   ],
   "source": [
    "# Registrar el experimento en el Model Registry\n",
    "model_registry_name = \"colome-modelos\"\n",
    "\n",
    "try:\n",
    "    client.get_registered_model(model_registry_name)\n",
    "    print(f\"El registro de modelos '{model_registry_name}' ya existe.\")\n",
    "except:\n",
    "    client.create_registered_model(model_registry_name)\n",
    "    print(f\"Registro de modelos '{model_registry_name}' creado.\")\n",
    "\n",
    "\n",
    "# Asignar Champion y Challenger\n",
    "if len(runs) >= 2:\n",
    "    # Run con mayor accuracy\n",
    "    best_run = runs[0]\n",
    "    second_best_run = runs[1]\n",
    "\n",
    "    # Registrar modelos\n",
    "    best_model_version = client.create_model_version(\n",
    "        name=model_registry_name,\n",
    "        source=f\"runs:/{best_run.info.run_id}/model\",  # Ruta del modelo en la run\n",
    "        run_id=best_run.info.run_id\n",
    "    )\n",
    "\n",
    "    second_best_model_version = client.create_model_version(\n",
    "        name=model_registry_name,\n",
    "        source=f\"runs:/{second_best_run.info.run_id}/model\",\n",
    "        run_id=second_best_run.info.run_id\n",
    "    )\n",
    "\n",
    "    # Asignar Champion\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_registry_name,\n",
    "        version=best_model_version.version,\n",
    "        stage=\"Production\"\n",
    "    )\n",
    "    client.set_registered_model_alias(model_registry_name, \"Champion\", best_model_version.version)\n",
    "\n",
    "    # Asignar Challenger\n",
    "    client.transition_model_version_stage(\n",
    "        name=model_registry_name,\n",
    "        version=second_best_model_version.version,\n",
    "        stage=\"Staging\"\n",
    "    )\n",
    "    client.set_registered_model_alias(model_registry_name, \"Challenger\", second_best_model_version.version)\n",
    "\n",
    "    print(f\"Champion: Run ID {best_run.info.run_id}, Accuracy: {best_run.data.metrics['accuracy']}\")\n",
    "    print(f\"Challenger: Run ID {second_best_run.info.run_id}, Accuracy: {second_best_run.data.metrics['accuracy']}\")\n",
    "else:\n",
    "    print(\"No hay suficientes runs para asignar Champion y Challenger.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
