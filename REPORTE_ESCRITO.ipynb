{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6276fd-2cf0-4994-8134-c64b14bbb4c1",
   "metadata": {},
   "source": [
    "### Juan Pedro Ley Valdez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb69068-e602-4c57-b2c1-6f93b221af0b",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "Este proyecto tiene como meta revisar nuestros conocimientos como data scientists en el desarrollo de un proyecto. Haremos un análisis exploratorio, ingeniería de características y orquestación y entrenamiento de modelos con mlflow y prefect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb5e81b-f68d-49df-a947-07f890ecc9d2",
   "metadata": {},
   "source": [
    "## Ingeniería de características\n",
    "El enfoque principal fue transformar los datos de texto crudos para su posterior análisis y modelado. Se realizó una limpieza de datos y se manejaron valores faltantes eliminando las quejas vacías. Luego, se realizó ingeniería de características, incluyendo la vectorización de características de texto usando un vectorizador TF-IDF y la codificación de etiquetas categóricas mediante LabelEncoder. Esta transformación de datos fue fundamental para preparar el conjunto de datos para entrenar modelos de aprendizaje automático más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf11492-bf0d-41ef-a650-ce77906ce880",
   "metadata": {},
   "source": [
    "## EDA\n",
    "Aquí nos centramos en analizar el conjunto de datos de forma visual y estadística para comprender las distribuciones, correlaciones y patrones subyacentes de las características. Se generaron varios gráficos, como histogramas, diagramas de barras y WordClods, para explorar las distribuciones de las quejas y sus categorías asociadas. Los conocimientos obtenidos del EDA ayudaron a identificar características importantes que influyeron en la selección de variables y guiaron el proceso de entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93488721-4b1a-46dc-84fb-1f62b7e4ced6",
   "metadata": {},
   "source": [
    "## Model Experiments\n",
    "A grandes rasgos en esta carpeta lo que hicimos fue hacer experimentos a mano para experimentar con los mejores tipos de modelos, se eligió Logistic Regression y Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7d380-2e40-42d6-8293-d9deb5eebf9b",
   "metadata": {},
   "source": [
    "## Training Pipeline\n",
    "En esta carpeta se implementa un pipeline de entrenamiento completo para los modelos Random Forest y Logistic Regression utilizando la librería Prefect. Primero, se lee y limpia un archivo JSON con datos sobre tickets de clasificación de problemas financieros, transformándolo en un DataFrame que contiene las columnas necesarias para la clasificación. Luego, se realiza una vectorización de los textos utilizando TF-IDF y una codificación de etiquetas con un LabelEncoder. Posteriormente, se entrena y optimizan los hiperparámetros de ambos modelos utilizando hyperopt y se registran los mejores modelos como \"Champion\" o \"Challenger\" utilizando MLflow y DagsHub. Finalmente, el flujo se ejecuta para entrenar y registrar los modelos, proporcionando un flujo completo para la automatización del entrenamiento y la gestión de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a6d82-fd2f-4587-9214-e80d852348f9",
   "metadata": {},
   "source": [
    "## Aplicación\n",
    "La aplicación se compone de una API creada con FastAPI que permite servir un modelo de clasificación de tickets, entrenado previamente utilizando el Champion.\n",
    "La interfaz de usuario fue construida usando Streamlit, permitiendo que un usuario ingrese una queja y obtenga la clasificación correspondiente de una manera amigable. Docker se utiliza para encapsular la API y la UI, proporcionando un entorno consistente para la ejecución de ambos componentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da49fd-1401-4432-bcb8-579bcb8bc8f1",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "Este proyectó sirvió como una manera de encapsular todo lo que aprendimos a lo largo del semestre. La verdad fue un reto hacer todo esto en la ventana de tiempo dada para realizar el exámen, pero los retos que superé en el proceso me ayudaron a tener mas confianza en mis capacidades como Data Scientist.\n",
    "\n",
    "Lo que me pareció mas genial del proyecto fue el hecho de que lo que estamos haciendo es un proceso de MLOps automatizado y aprendí mucho sobre el deployment de modelos este semestre"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
