{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXAMEN FINAL - Reporte Escrito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juan Pablo Colomé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este examen se tienen que cumplir los siguientes requisitos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizar `mlflow` para realizar experimentos y registrar modelos, por lo que debe enlazar su repositorio de `github` con `dagshub`\n",
    "\n",
    "- Debe abordar, como mínimo, los aspectos básicos de un proyecto de ciencia de datos, incluyendo:\n",
    "  - **Análisis Exploratorio de Datos.**\n",
    "\n",
    "  - **Ingeniería de Características - Data Wrangling.**\n",
    "\n",
    "  - **Entrenamiento, validación, evaluación y selección del modelo usando `mlflow`:**\n",
    "    - Realice **tracking de experimentos** con al menos **dos modelos diferentes**.\n",
    "    - Implemente **hyperparameter tuning** para cada modelo.\n",
    "    - Asigne nombres a los experimentos.\n",
    "\n",
    "    - Registre el modelo con mejor desempeño como **Champion** y el segundo mejor como **Challenger** en el Model Registry.\n",
    "    - Cree un nuevo modelo en el Model Registry con un nombre.\n",
    "      \n",
    "    - **Orquestación del flujo de entrenamiento:**\n",
    "      - Use un **cuaderno Jupyter** para documentar sus experimentos iniciales y hacer el setting con el servidor de `mlflow`.\n",
    "      - Cree un **script con Prefect** que orqueste el flujo de entrenamiento y registre los modelos.\n",
    "      - El flujo debe ser ejecutable en local, realizar el tracking en `mlflow`, y asegurar el registro de los modelos.\n",
    "\n",
    "  - **Microservicio (API) para servir el modelo:**\n",
    "    - Utilice `fastapi` (o cualquier framework con el que se sienta cómodo trabajando) para crear una API y servir el modelo previamente entrenado.\n",
    "    - La API debe usar el modelo **Champion** para realizar inferencias.\n",
    "\n",
    "  -  **Frontend:**\n",
    "    - Cree una interfaz de usuario sencilla para conectarla con la API del modelo y poder servir las inferencias\n",
    "    - Utilice `streamlit` o cualquier otro framework con el que se sienta cómodo trabajando\n",
    "\n",
    "  - **Creación de contenedores**\n",
    "    - Utilice un archivo `docker-compose.yaml` para ejecutar los contenedores de la API y el frontend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. ANÁLISIS EXPLORATORIO DE DATOS y DATA WRANGLING\n",
    "\n",
    "- Este se encuentra en la carpeta de 'notebooks' siendo un notebook llamado eda.\n",
    "- Este recibe los datos crudos de la carpeta de raw_data, los limpia, preprocesa, hace data wrangling, feature engineering y guarda los nuevos datos en la carpeta llamada data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. TRACKING DE MODELOS CON MLFLOW\n",
    "- Esto se trabaja en un notebook que se llama train, dentro de la carpeta 'notebooks'.\n",
    "- Dentro de este, se entrenan modelos de regresión logistica y random forest.\n",
    "- Se lleva acabo unproceso de hyper parameter tuning con gridsearch.\n",
    "- Se hace log de métricas, parámetros y modelos a mlflow.\n",
    "- Se hace model registry y se asignan aliases 'Champion' y 'Challenger' a los dos mejores modelos según sus métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. ORQUESTACIÓN DE PREFECT\n",
    "- Este es un archivo .py llamado trainig_pipeline que esta dentro de la carpeta training_pipeline. \n",
    "- Este lleva a cabo lo misom que el notebook de tracking de modelos pero a través de tasks y un flow de prefect.\n",
    "- En este archivo se incluye el guardado y el log de los artefactos de tfifd y label encoder los cuales fueron guardados en la carpeta models como .pkl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. API O BACKEND\n",
    "- Para esta parte se creo la carpeta llamada api.\n",
    "- Dentro esta un archivo llamado main.py donde se crea la aplicación de fastapi y se le pasan el modelo champion y los artefactos para poder hacer predicciones con estos. Se usa la api para pasar nuevas quejas y que las pueda clasificar.\n",
    "- Tiene una carpeta models con los artefactos, se la pase para que pueda acceder a ellos más fácilmente.\n",
    "- Se uso postman para verificar que funcione.\n",
    "- Hay otro archivo llamado dockerfile, el cual tiene las instrucciones para crear la imagen de la api.\n",
    "- Tiene un requirements.txt con sus dependencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. FRONTEND\n",
    "- Para esta parte se crea otra carpeta llamada frontend.\n",
    "- Dentro de esta hay un archivo .py llamado app, el cual tiene el código para crear la aplicación en streamlit.\n",
    "- Este también se conecta con la api para poder hacer post de nuevas quejas en la aplicación.\n",
    "- También tiene un archivo dockerfile con las instrucciones para la creación de su imagen.\n",
    "- Tiene un requirements.txt con sus dependencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. CREACIÓN DE CONTENEDORES\n",
    "- Usamos un archivo .yaml que se llama docker-compose. \n",
    "- Este crea los contenedores de cada imagen, es decir, crea los contenedores de la api y del frontend.\n",
    "- De esta manera podemos hacer que las predicciones y la aplicación funcionen juntas y así lleguemos a nuestro objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONCLUSIÓN\n",
    "- Este examen funciono como un proyecto. Definitivamente, mientras más avanzaba más complicado se ponía. Hacer modelos ya no es un reto para mi, bueno, no tanto. Por eso no hubo tanto enfoque en esa parte, ya sabía que me iba a tomar mucho tiempo en lo demás, por eso el modelo no tuvo tan buen rendimiento.\n",
    "\n",
    "- El tracking de modelos, aunque fue difícil, no fue lo más retador. Crear el frontend y backend fue lo más difícil para mi. Lo bueno es que le saque mucho provecho al examen, ya que fue individual. Pude aprender mucho y logré entender cosas que no entendía antes.\n",
    "\n",
    "- Aunque el modelo no haya sido tan bueno, haberlo llevado de nada, hasta una aplicación que pueda clasificar nuevos comentarios es un logro para mi. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
